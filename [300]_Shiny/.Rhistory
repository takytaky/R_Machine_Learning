for(j in 1:7){
# Boostrap
T_Data <- data.frame(f = OutPut, x = InPut)
Test_INDEX <- sample(1:length(InPut), size = 7, replace = FALSE)
Train_Data <- T_Data[-Test_INDEX, ]
Test_Data <- T_Data[Test_INDEX, ]
Model_T2 <- lm(f ~ poly(x, i), data = Train_Data)
Pred_Model_Each[[j]] <- data.frame(x = Test_Data$x,
predict.lm(Model_T2,
newdata = Test_Data))
}
Pred_Degree[[i]] <- Pred_Model_Each
}
for(j in 1:9){
Plot_Name <- paste0(j, " Degree")
plot(InPut, OutPut,
xlim = c(-10, 10),
ylim = c(-1.8, 1.8),
main = Plot_Name, cex = 0.6)
for(i in 1:7){
lines(Pred_Degree[[j]][[i]][ ,1],
Pred_Degree[[j]][[i]][ ,2],
col = rainbow(6)[i],
lwd = 3)
}
}
par(mfrow = c(1, 1))
for(j in 1:9){
Plot_Name <- paste0(j, " Degree")
plot(InPut, OutPut,
xlim = c(-10, 10),
ylim = c(-1.8, 1.8),
main = Plot_Name, cex = 0.6)
for(i in 1:7){
lines(Pred_Degree[[j]][[i]][ ,1],
Pred_Degree[[j]][[i]][ ,2],
col = rainbow(10)[i],
lwd = 3)
}
}
x <- sort(round(runif(100, 33, 88), 3))
y <- sort(round(runif(100, 0, 10), 3))
z <- rnorm(100, mean = 0, sd = 2)
x <- x + z
y <- y + z
plot(x, y, pch = 19)
cor(x, y)
Model_lm <- lm(y ~ x)
structure(Model_lm)
coef(Model_lm)
abline(Model_lm, col="red", lwd = 3)
w <- Model_lm$coefficients[["x"]]
b <- Model_lm$coefficients[["(Intercept)"]]
y_hat = w * 53 + b
predict(Model_lm,
newdata = data.frame(x = 53))
points(x, fitted(Model_lm), col = "blue", cex = 1.5)
predict(Model_lm,
newdata = data.frame(x = 53),
interval = "confidence")
library(ggplot2)
ggplot(data.frame(x, y), aes(x,y)) +
geom_point() +
stat_smooth(method = "lm")
summary(Model_lm)
강도 <- c(82.8, 119.4, 105.5, 154.3, 139.5, 65.6, 88.9, 114.1)
온도 <- c(199, 181, 203, 207, 202, 188, 211, 210)
시간 <- c(59, 62, 58, 63, 60, 55, 57, 62)
Model_mr <- lm(강도 ~ 온도 + 시간)
coef(Model_mr)
w1 <- Model_mr$coefficients[["온도"]]
w2 <- Model_mr$coefficients[["시간"]]
b <- Model_mr$coefficients[["(Intercept)"]]
y_hat2 <- w1 * 199 + w2 * 62 + b
predict(Model_mr,
newdata = data.frame("온도" = 199, "시간" = 62),
interval = "confidence")
summary(Model_mr)
library(car)
vif(Model_mr)
iris <- read.csv("mlData/Iris.csv")
head(iris)
Model_VIF <- lm(Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width, iris)
vif(Model_VIF)
cor(iris[, 2:4])
Model_VIF_A <- lm(Sepal.Length ~ Sepal.Width + Petal.Length, iris)
vif(Model_VIF_A)
Model_VIF_B <- lm(Sepal.Length ~ Sepal.Width + Petal.Width, iris)
vif(Model_VIF_B)
Model_VIF_C <- lm(Sepal.Length ~ Petal.Length + Petal.Width, iris)
vif(Model_VIF_C)
library(plotly)
library(reshape2)
petal_lm <- lm(Petal.Length ~ Sepal.Length + Sepal.Width, iris)
graph_reso <- 0.05
axis_x <- seq(min(iris$Sepal.Length),
max(iris$Sepal.Length),
by = graph_reso)
axis_y <- seq(min(iris$Sepal.Width),
max(iris$Sepal.Width),
by = graph_reso)
petal_lm_surface <- expand.grid(Sepal.Length = axis_x,
Sepal.Width = axis_y,
KEEP.OUT.ATTRS = FALSE)
petal_lm_surface$Petal.Length <- predict.lm(petal_lm,
newdata = petal_lm_surface)
petal_lm_surface <- acast(petal_lm_surface,
Sepal.Width ~ Sepal.Length,
value.var = "Petal.Length")
hcolors=c("red","blue","green")[iris$Species]
iris_plot <- plot_ly(iris,
x = ~Sepal.Length,
y = ~Sepal.Width,
z = ~Petal.Length,
text = ~Species,
type = "scatter3d",
mode = "markers",
marker = list(color = hcolors))
iris_plot <- add_trace(p = iris_plot,
z = petal_lm_surface,
x = axis_x,
y = axis_y,
type = "surface")
iris_plot
Insure_Data <- read.csv("mlData/insurance.csv")
head(Insure_Data)
set.seed(2045)
Train_Index <- sample(1:nrow(Insure_Data), nrow(Insure_Data) * 0.7)
Train_Data <- Insure_Data[Train_Index, ]
Test_Data <- Insure_Data[-Train_Index, ]
Test_Expenses <- Test_Data$expenses
Test_Data <- Test_Data[, -7]
ggplot(Train_Data, aes(x = 0, y = expenses)) +
geom_boxplot()
ggplot(Train_Data, aes(x = sex, y = expenses)) +
geom_boxplot(aes(fill = sex))
ggplot(Train_Data, aes(x = factor(children), y = expenses)) +
geom_boxplot(aes(fill = factor(children)))
ggplot(Train_Data, aes(x = smoker, y = expenses)) +
geom_boxplot(aes(fill = smoker))
ggplot(Train_Data, aes(x = region, y = expenses)) +
geom_boxplot(aes(fill = region))
Model_1 <- lm(expenses ~ ., Train_Data)
Pred_Expenses_1 <- predict(Model_1, Test_Data)
rMSE <- function(actual, predict){
if(length(actual) != length(predict)){
stop("Length Error")
}
COUNT <- length(actual)
RSS <- sum((actual - predict)^2)
return(sqrt(RSS/COUNT))
}
MSE1 <- rMSE(Test_Expenses, Pred_Expenses_1)
Model_2 <- lm(expenses ~ bmi + smoker + children + sex, Train_Data)
Pred_Expenses_2 <- predict(Model_2, Test_Data)
MSE2 <- rMSE(Test_Expenses, Pred_Expenses_2)
Model_3 <- lm(expenses ~ bmi + smoker + age, Train_Data)
Pred_Expenses_3 <- predict(Model_3, Test_Data)
MSE3 <- rMSE(Test_Expenses, Pred_Expenses_3)
Model_4 <- lm(expenses ~ . -region, Train_Data)
Pred_Expenses_4 <- predict(Model_4, Test_Data)
MSE4 <- rMSE(Test_Expenses, Pred_Expenses_4)
Model_5 <- lm(expenses ~ bmi + smoker + age + children, Train_Data)
Pred_Expenses_5 <- predict(Model_5, Test_Data)
MSE5 <- rMSE(Test_Expenses, Pred_Expenses_5)
Model_6 <- lm(expenses ~ bmi + smoker + age + children + region, Train_Data)
Pred_Expenses_6 <- predict(Model_6, Test_Data)
MSE6 <- rMSE(Test_Expenses, Pred_Expenses_6)
MSE1 ; MSE2 ; MSE3 ; MSE4 ; MSE5 ; MSE6
sigmoid <- function(x){
y <- 1 / (1 + exp(-x))
return(y)
}
sigmoid(0)
sigmoid(100000000)
sigmoid(-100000000)
C_Machine <- function(x, w, b){
y_hat <- sigmoid(w * x + b)
return(y_hat)
}
A <- 0.6 ; B <- 0.3 ; C <- 0.1
(I_A <- -log(A))
(I_B <- -log(B))
(I_C <- -log(C))
AlphaGo <- 0.99 ; Apes <- 0.01
(I_AlphaGo <- -log(AlphaGo))
(I_Apes <- -log(Apes))
P1 <- 0.99 ; P2 <- 0.01
(E1 <- -P1 * log(P1) - P2 * log(P2))
P1 <- 0.5 ; P2 <- 0.5
(E2 <- -P1 * log(P1) - P2 * log(P2))
E1 ; E2
Cost <- function(x, y, w, b){
y_hat <- C_Machine(x, w, b)
loss <- -y * log(y_hat) - (1 - y) * log(1 - y_hat)
cost <- mean(loss)
return(cost)
}
Trainer <- function(x, y, w, b, step){
dw <- (Cost(x, y, w + 0.0001, b) - Cost(x, y, w, b)) / 0.0001
db <- (Cost(x, y, w, b + 0.0001) - Cost(x, y, w, b)) / 0.0001
w <- w - step * dw
b <- b - step * db
return(c(w, b))
}
Default <- read.csv("mlData/Default.csv")
str(Default)
head(Default)
table(Default$default)
plot(Default$balance ~ Default$default)
y <- ifelse(Default$default == "Yes", 1, 0)
table(y)
BLC <- Default$balance
range(BLC)
plot(BLC, cex = 0.5)
boxplot(BLC)
range((BLC - mean(BLC)) / sd(BLC))
x <- (BLC - mean(BLC)) / sd(BLC)
range(x)
par(mfrow = c(2,2))
plot(BLC, cex = 0.5)
boxplot(BLC)
plot(x, cex = 0.5)
boxplot(x)
par(mfrow = c(1,1))
w <- 0
b <- 0
for(i in 1:5000){
temp <- Trainer(x, y, w, b, 0.5)
w <- temp[1]
b <- temp[2]
}
w
b
y_prob <- C_Machine(x, w, b)
head(y_prob)
y_label <- ifelse(y_prob > 0.5, "Yes", "No")
table(y_label)
table(Default$default, y_label,
dnn = c("Actual", "Predicted"))
table(Default$default, y_label,
dnn = c("실제", "분류(예측)"))
accuracy <- (9625 + 100)/(9625 + 42 + 233 + 100)
precision <- 9625/(9625 + 233)
recall <- 9625/(9625 + 42)
F_Score <- 2 * ((precision * recall) / (precision + recall))
F_Score
accuracy <- (9625 + 100)/(9625 + 42 + 233 + 100)
precision <- 100/(42 + 100)
recall <- 100/(233 + 100)
F_Score <- 2 * ((precision * recall) / (precision + recall))
F_Score
Model_lr <-  glm(y ~ x, family = "binomial")
Model_lr
y_prob2 <- predict(Model_lr, type = "response")
head(y_prob2)
y_label2 <- ifelse(y_prob2 > 0.5, 1, 0)
table(y, y_label2,
dnn = c("Actual", "Predicted"))
precision2 <- 100/(42 + 100)
recall2 <- 100/(233 + 100)
F_Score2 <- 2 * ((precision2 * recall2) / (precision2 + recall2))
F_Score2
Smarket <- read.csv("mlData/Smarket.csv")
str(Smarket)
head(Smarket)
Model_SM <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume,
data = Smarket,
family = binomial)
summary(Model_SM)
Pred_PB <- predict(Model_SM, type = "respons")
head(Pred_PB)
Pred_LR <- ifelse(Pred_PB > 0.5, "UP", "Down")
head(Pred_LR)
attach(Smarket)
table(Pred_LR, Direction,
dnn = c("Actual", "Predicted"))
recall_S <- 507/(457 + 507)
precision_S <- 507/(141 + 507)
F_Score_S <- 2 * ((precision_S * recall_S) / (precision_S + recall_S))
F_Score_S
library(nnet)
iris <- read.csv("mlData/IRIS.csv")
Model_MLR <- multinom(Species ~ ., iris)
head(fitted(Model_MLR))
tail(head(fitted(Model_MLR), 80))
tail(fitted(Model_MLR))
Pred_MLR_P <- predict(Model_MLR, newdata = iris, type = "probs")
head(Pred_MLR_P)
Pred_MLR_C <- predict(Model_MLR, newdata = iris, type = "class")
head(Pred_MLR_C)
xtabs(~ Pred_MLR_C + iris$Species)
getwd()
swrwd("~")
setwd("~")
rMSE <- function(actual, predict){
if(length(actual) != length(predict)){
stop("Length Error")
}
COUNT <- length(actual)
MSE <- mean((actual - predict)^2)
return(MSE)
}
set.seed(2045)
Train_Index <- sample(1:nrow(Insure_Data), nrow(Insure_Data) * 0.7)
Insure_Data <- read.csv("mlData/insurance.csv")
head(Insure_Data)
set.seed(2045)
Train_Index <- sample(1:nrow(Insure_Data), nrow(Insure_Data) * 0.7)
Train_Data <- Insure_Data[Train_Index, ]
Test_Data <- Insure_Data[-Train_Index, ]
Test_Expenses <- Test_Data$expenses
Test_Data <- Test_Data[, -7]
Model_1 <- lm(expenses ~ ., Train_Data)
Pred_Expenses_1 <- predict(Model_1, Test_Data)
rMSE <- function(actual, predict){
if(length(actual) != length(predict)){
stop("Length Error")
}
COUNT <- length(actual)
MSE <- mean((actual - predict)^2)
return(MSE)
}
MSE1 <- rMSE(Test_Expenses, Pred_Expenses_1)
Model_2 <- lm(expenses ~ bmi + smoker + children + sex, Train_Data)
Pred_Expenses_2 <- predict(Model_2, Test_Data)
MSE2 <- rMSE(Test_Expenses, Pred_Expenses_2)
Model_3 <- lm(expenses ~ bmi + smoker + age, Train_Data)
Pred_Expenses_3 <- predict(Model_3, Test_Data)
MSE3 <- rMSE(Test_Expenses, Pred_Expenses_3)
Model_4 <- lm(expenses ~ . -region, Train_Data)
Pred_Expenses_4 <- predict(Model_4, Test_Data)
MSE4 <- rMSE(Test_Expenses, Pred_Expenses_4)
Model_5 <- lm(expenses ~ bmi + smoker + age + children, Train_Data)
Pred_Expenses_5 <- predict(Model_5, Test_Data)
MSE5 <- rMSE(Test_Expenses, Pred_Expenses_5)
Model_6 <- lm(expenses ~ bmi + smoker + age + children + region, Train_Data)
Pred_Expenses_6 <- predict(Model_6, Test_Data)
MSE6 <- rMSE(Test_Expenses, Pred_Expenses_6)
MSE1 ; MSE2 ; MSE3 ; MSE4 ; MSE5 ; MSE6
rMSE <- function(actual, predict){
if(length(actual) != length(predict)){
stop("Length Error")
}
COUNT <- length(actual)
MSE <- mean((actual - predict)^2)
return(sqrt(MSE))
}
MSE1 <- rMSE(Test_Expenses, Pred_Expenses_1)
Model_2 <- lm(expenses ~ bmi + smoker + children + sex, Train_Data)
Pred_Expenses_2 <- predict(Model_2, Test_Data)
MSE2 <- rMSE(Test_Expenses, Pred_Expenses_2)
Model_3 <- lm(expenses ~ bmi + smoker + age, Train_Data)
Pred_Expenses_3 <- predict(Model_3, Test_Data)
MSE3 <- rMSE(Test_Expenses, Pred_Expenses_3)
Model_4 <- lm(expenses ~ . -region, Train_Data)
Pred_Expenses_4 <- predict(Model_4, Test_Data)
MSE4 <- rMSE(Test_Expenses, Pred_Expenses_4)
Model_5 <- lm(expenses ~ bmi + smoker + age + children, Train_Data)
Pred_Expenses_5 <- predict(Model_5, Test_Data)
MSE5 <- rMSE(Test_Expenses, Pred_Expenses_5)
Model_6 <- lm(expenses ~ bmi + smoker + age + children + region, Train_Data)
Pred_Expenses_6 <- predict(Model_6, Test_Data)
MSE6 <- rMSE(Test_Expenses, Pred_Expenses_6)
MSE1 ; MSE2 ; MSE3 ; MSE4 ; MSE5 ; MSE6
sigmoid <- function(x){
y <- 1 / (1 + exp(-x))
return(y)
}
sigmoid(0)
sigmoid(100000000)
sigmoid(-100000000)
A <- 0.6 ; B <- 0.3 ; C <- 0.1
(I_A <- -log(A))
(I_B <- -log(B))
(I_C <- -log(C))
AlphaGo <- 0.99 ; Apes <- 0.01
(I_AlphaGo <- -log(AlphaGo))
(I_Apes <- -log(Apes))
P1 <- 0.99 ; P2 <- 0.01
(E1 <- -P1 * log(P1) - P2 * log(P2))
P1 <- 0.5 ; P2 <- 0.5
(E2 <- -P1 * log(P1) - P2 * log(P2))
E1 ; E2
C_Machine <- function(x, w, b){
y_hat <- sigmoid(w * x + b)
return(y_hat)
}
Cost <- function(x, y, w, b){
y_hat <- C_Machine(x, w, b)
loss <- -y * log(y_hat) - (1 - y) * log(1 - y_hat)
cost <- mean(loss)
return(cost)
}
Trainer <- function(x, y, w, b, step){
dw <- (Cost(x, y, w + 0.0001, b) - Cost(x, y, w, b)) / 0.0001
db <- (Cost(x, y, w, b + 0.0001) - Cost(x, y, w, b)) / 0.0001
w <- w - step * dw
b <- b - step * db
return(c(w, b))
}
Default <- read.csv("mlData/Default.csv")
str(Default)
head(Default)
table(Default$default)
plot(Default$balance ~ Default$default)
y <- ifelse(Default$default == "Yes", 1, 0)
table(y)
BLC <- Default$balance
range(BLC)
plot(BLC, cex = 0.5)
boxplot(BLC)
range((BLC - mean(BLC)) / sd(BLC))
x <- (BLC - mean(BLC)) / sd(BLC)
range(x)
par(mfrow = c(2,2))
plot(BLC, cex = 0.5)
boxplot(BLC)
plot(x, cex = 0.5)
boxplot(x)
par(mfrow = c(1,1))
w <- 0
b <- 0
for(i in 1:5000){
temp <- Trainer(x, y, w, b, 0.5)
w <- temp[1]
b <- temp[2]
}
w
b
y_prob <- C_Machine(x, w, b)
head(y_prob)
y_label <- ifelse(y_prob > 0.5, "Yes", "No")
table(y_label)
table(Default$default, y_label,
dnn = c("Actual", "Predicted"))
table(Default$default, y_label,
dnn = c("실제", "분류(예측)"))
accuracy <- (9625 + 100)/(9625 + 42 + 233 + 100)
precision <- 9625/(9625 + 233)
recall <- 9625/(9625 + 42)
F_Score <- 2 * ((precision * recall) / (precision + recall))
F_Score
accuracy <- (9625 + 100)/(9625 + 42 + 233 + 100)
precision <- 100/(42 + 100)
recall <- 100/(233 + 100)
F_Score <- 2 * ((precision * recall) / (precision + recall))
F_Score
Model_lr <-  glm(y ~ x, family = "binomial")
Model_lr
y_prob2 <- predict(Model_lr, type = "response")
head(y_prob2)
y_label2 <- ifelse(y_prob2 > 0.5, 1, 0)
table(y, y_label2,
dnn = c("Actual", "Predicted"))
precision2 <- 100/(42 + 100)
recall2 <- 100/(233 + 100)
F_Score2 <- 2 * ((precision2 * recall2) / (precision2 + recall2))
F_Score2
Smarket <- read.csv("mlData/Smarket.csv")
str(Smarket)
head(Smarket)
Model_SM <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume,
data = Smarket,
family = "binomial")
summary(Model_SM)
Pred_PB <- predict(Model_SM, type = "respons")
head(Pred_PB)
Pred_LR <- ifelse(Pred_PB > 0.5, "UP", "Down")
head(Pred_LR)
attach(Smarket)
table(Pred_LR, Direction,
dnn = c("Actual", "Predicted"))
recall_S <- 507/(457 + 507)
precision_S <- 507/(141 + 507)
F_Score_S <- 2 * ((precision_S * recall_S) / (precision_S + recall_S))
F_Score_S
library(nnet)
iris <- read.csv("mlData/IRIS.csv")
Model_MLR <- multinom(Species ~ ., iris)
head(fitted(Model_MLR))
tail(head(fitted(Model_MLR), 80))
tail(fitted(Model_MLR))
Pred_MLR_P <- predict(Model_MLR, newdata = iris, type = "probs")
head(Pred_MLR_P)
Pred_MLR_C <- predict(Model_MLR, newdata = iris, type = "class")
head(Pred_MLR_C)
xtabs(~ Pred_MLR_C + iris$Species)
iris
str(iris)
head(iris)
set.seed(2045)
IDX_TR <- sample(1:nrow(iris), nrow(iris) * 0.7)
Iris_TR <- iris[IDX_TR, ]
dim(Iris_TR)
Iris_VD <- iris[-IDX_TR, ]
dim(Iris_VD)
library(nnet)
library(NeuralNetTools)
Model_nn_1 <- nnet(Species ~ . - Sepal.Length, Iris_TR, size = 1)
plotnet(Model_nn_1)
structure(Model_nn_1)
summary(Model_nn_1)
Pred_Spec_1 <- predict(Model_nn_1, Iris_VD, type = "class")
table(Iris_VD$Species, Pred_Spec_1)
Model_nn_3 <- nnet(Species ~ . - Sepal.Length, Iris_TR, size = 3)
plotnet(Model_nn_3)
structure(Model_nn_3)
summary(Model_nn_3)
Pred_Spec_3 <- predict(Model_nn_3, Iris_VD, type = "class")
table(Iris_VD$Species, Pred_Spec_3)
shiny::runApp('[333]_Shiny')
